{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of float64 type data:96\n",
      "Number of object type data:4\n"
     ]
    }
   ],
   "source": [
    "# Data Exploration looking for data types.\n",
    "test_set = pd.read_csv('statef_test.csv')\n",
    "number_of_obj_type_test = []\n",
    "index_of_obj_test = []\n",
    "number_of_float_type_test = 0\n",
    "\n",
    "data_types_test = test_set.dtypes\n",
    "for i in range(0,100):\n",
    "    \n",
    "    if data_types_test[i] == 'float64':\n",
    "\n",
    "        number_of_float_type_test= number_of_float_type_test+1\n",
    "    \n",
    "    elif data_types_test[i] == 'object':\n",
    "\n",
    "        number_of_obj_type_test.append(data_types_test[i])\n",
    "        index_of_obj_test.append( data_types_test.index[i])\n",
    "        \n",
    "        \n",
    "print('Number of float64 type data:' + str(number_of_float_type_test))\n",
    "print('Number of object type data:' + str(len(number_of_obj_type_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data input train data here \n",
    "def clean_statef_training (exel_file):\n",
    "# Minizinging double or repeated data\n",
    "# Cleaning    \n",
    "    data = pd.read_csv(exel_file)\n",
    "    data['x35'].replace('thurday','Thursday',inplace=True)\n",
    "    data['x35'].replace('thur','Thursday',inplace=True)\n",
    "    data['x35'].replace(['fri','Friday'],'Friday',inplace=True)\n",
    "    data['x35'].replace('wed','Wednesday',inplace=True)\n",
    "    data['x35'].replace('wednesday','Wednesday',inplace=True)\n",
    "    data['x35'].replace('tuesday','Tuesday',inplace=True)\n",
    "    data['x35'].replace('monday','Monday',inplace=True)\n",
    "    data['x68'].replace('July','Jul',inplace=True)\n",
    "    data['x68'].replace('sept.','Sep',inplace=True)\n",
    "    data['x68'].replace('January','Jan',inplace=True)\n",
    "    data['x68'].replace('Dev','Dec',inplace=True)\n",
    "# cleaning string type to categories    \n",
    "# Dealing with nan    \n",
    "    data['x34']=data['x34'].str.capitalize()\n",
    "    fill_values={'x34':'Other', 'x93': 'Other', 'x35':'Other', 'x68':'Unknown'}\n",
    "    data.fillna(value=fill_values,inplace=True)\n",
    "    data = data.copy()\n",
    "    data['x34'] = data['x34'].astype('category',order = True)\n",
    "    data['x34'] = data['x34'].cat.codes\n",
    "    data['x68'] = data['x68'].astype('category',order = True)\n",
    "    data['x68'] = data['x68'].cat.codes\n",
    "    data['x35'] = data['x35'].astype('category',order = True)\n",
    "    data['x35'] = data['x35'].cat.codes\n",
    "    data['x93'] = data['x93'].astype('category',order = True)\n",
    "    data['x93'] = data['x93'].cat.codes\n",
    "#Filling missing values     \n",
    "    train_set = data.apply(lambda x: x.fillna(x.mean()),axis=0)\n",
    "    return train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Phase input test data here.\n",
    "def clean_statef_testing (exel_file):\n",
    "\n",
    "# Minizinging double or repeated data\n",
    "# Cleaning\n",
    "    test_set = pd.read_csv(exel_file)\n",
    "    test_set['x35'].replace('thurday','Thursday',inplace=True)\n",
    "    test_set['x35'].replace('thur','Thursday',inplace=True)\n",
    "    test_set['x35'].replace(['fri','Friday'],'Friday',inplace=True)\n",
    "    test_set['x35'].replace('wed','Wednesday',inplace=True)\n",
    "    test_set['x35'].replace('wednesday','Wednesday',inplace=True)\n",
    "    test_set['x35'].replace('tuesday','Tuesday',inplace=True)\n",
    "    test_set['x35'].replace('monday','Monday',inplace=True)\n",
    "    test_set['x68'].replace('July','Jul',inplace=True)\n",
    "    test_set['x68'].replace('sept.','Sep',inplace=True)\n",
    "    test_set['x68'].replace('January','Jan',inplace=True)\n",
    "    test_set['x68'].replace('Dev','Dec',inplace=True)    \n",
    "# cleaning string type to categories    \n",
    "# Dealing with nan \n",
    "    test_set['x34']=test_set['x34'].str.capitalize()\n",
    "    fill_values={'x34':'Other', 'x93': 'Other', 'x35':'Other', 'x68':'Unknown'}\n",
    "    test_set.fillna(value=fill_values,inplace=True)\n",
    "    test_set = test_set.copy()\n",
    "    test_set['x34'] = test_set['x34'].astype('category',order = True)\n",
    "    test_set['x34'] = test_set['x34'].cat.codes\n",
    "    test_set['x68'] = test_set['x68'].astype('category',order = True)\n",
    "    test_set['x68'] = test_set['x68'].cat.codes\n",
    "    test_set['x35'] = test_set['x35'].astype('category',order = True)\n",
    "    test_set['x35'] = test_set['x35'].cat.codes\n",
    "    test_set['x93'] = test_set['x93'].astype('category',order = True)\n",
    "    test_set['x93'] = test_set['x93'].cat.codes\n",
    "#Filling missing values    \n",
    "    testing_set = test_set.apply(lambda x: x.fillna(x.mean()),axis=0)\n",
    "    return testing_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "36000/36000 [==============================] - 5s 126us/sample - loss: 0.2488 - accuracy: 0.9016 - val_loss: 0.1332 - val_accuracy: 0.9595\n",
      "Epoch 2/10\n",
      "36000/36000 [==============================] - 4s 104us/sample - loss: 0.1016 - accuracy: 0.9680 - val_loss: 0.1036 - val_accuracy: 0.9682\n",
      "Epoch 3/10\n",
      "36000/36000 [==============================] - 4s 115us/sample - loss: 0.0729 - accuracy: 0.9787 - val_loss: 0.0790 - val_accuracy: 0.9778\n",
      "Epoch 4/10\n",
      "36000/36000 [==============================] - 4s 105us/sample - loss: 0.0611 - accuracy: 0.9830 - val_loss: 0.0777 - val_accuracy: 0.9808\n",
      "Epoch 5/10\n",
      "36000/36000 [==============================] - 4s 109us/sample - loss: 0.0548 - accuracy: 0.9846 - val_loss: 0.1351 - val_accuracy: 0.9605\n",
      "Epoch 6/10\n",
      "36000/36000 [==============================] - 4s 112us/sample - loss: 0.0498 - accuracy: 0.9859 - val_loss: 0.0728 - val_accuracy: 0.9822\n",
      "Epoch 7/10\n",
      "36000/36000 [==============================] - 6s 163us/sample - loss: 0.0438 - accuracy: 0.9878 - val_loss: 0.0772 - val_accuracy: 0.9812\n",
      "Epoch 8/10\n",
      "36000/36000 [==============================] - 7s 182us/sample - loss: 0.0416 - accuracy: 0.9882 - val_loss: 0.0830 - val_accuracy: 0.9818\n",
      "Epoch 9/10\n",
      "36000/36000 [==============================] - 4s 99us/sample - loss: 0.0382 - accuracy: 0.9891 - val_loss: 0.0885 - val_accuracy: 0.9825\n",
      "Epoch 10/10\n",
      "36000/36000 [==============================] - 3s 97us/sample - loss: 0.0357 - accuracy: 0.9898 - val_loss: 0.0944 - val_accuracy: 0.9820\n"
     ]
    }
   ],
   "source": [
    "# Assinging features to X and labels to y\n",
    "train_data = clean_statef_training ('statef_train.csv')\n",
    "test_data = clean_statef_testing('statef_test.csv')\n",
    "\n",
    "X=train_data.drop(labels='y',axis=1)\n",
    "y = train_data['y']\n",
    "X_test = test_data\n",
    "\n",
    "# Model 1 XGBOOST \n",
    "\n",
    "import xgboost as xgs\n",
    "model3 = xgs.XGBClassifier(max_depth=11,n_estimators=300)\n",
    "model3.fit(X,y)\n",
    "ypred3 = model3.predict(X_test)\n",
    "result1 = pd.DataFrame(model3.predict_proba(X_test)[:,1])\n",
    "\n",
    "# Model 2 Deep-Neural Network\n",
    "X_train=tf.keras.utils.normalize(np.array(X),axis=1)\n",
    "y_train= np.array(y)\n",
    "# Tensorflow or Deeplearning Model\n",
    "X_test=tf.keras.utils.normalize(np.array(X_test),axis=1)\n",
    "mod1=tf.keras.models.Sequential()\n",
    "mod1.add(tf.keras.layers.Flatten())\n",
    "mod1.add(tf.keras.layers.Dense(100,activation=tf.nn.relu))\n",
    "mod1.add(tf.keras.layers.Dense(100,activation=tf.nn.relu))\n",
    "mod1.add(tf.keras.layers.Dense(50,activation=tf.nn.relu))\n",
    "#mod1.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "#mod1.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "#mod1.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "mod1.add(tf.keras.layers.Dense(2,activation=tf.nn.sigmoid))\n",
    "mod1.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'],lr=0.1,)\n",
    "mod1.fit(X_train,y_train,epochs=10,validation_split=0.10,batch_size=20,shuffle='Str',)\n",
    "result2 = pd.DataFrame(mod1.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1.to_csv('results2.csv',index=False,header=False)\n",
    "result2.to_csv('results1.csv',index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
